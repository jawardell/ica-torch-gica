{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub_id:001312269620\n",
      "func_file:/data/qneuromark/Data/FBIRN/ZN_Neuromark/ZN_Prep_fMRI/001312269620/SM.nii\n",
      "output_dir:./out/\n",
      "mask_file:/data/users2/jwardell1/nshor_docker/examples/fbirn-project/FBIRN/group_mean_masks/mask_resampled.nii\n",
      "template_file:/data/users2/jwardell1/ica-torch-gica/sa_script_work/gica/group_level_analysis/Neuromark_fMRI_1.0.nii\n",
      "src_data.shape torch.Size([157, 58104])\n",
      "ref_data.shape torch.Size([53, 58104])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3944648/3472944891.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  FmriMatr = torch.tensor(FmriMatr, dtype=torch.float64)\n",
      "/tmp/ipykernel_3944648/3472944891.py:111: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ICRefMax = torch.tensor(ICRefMax, dtype=torch.float64)\n",
      "/tmp/ipykernel_3944648/3472944891.py:136: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:240.)\n",
      "  Esort[:,i] = E[:,index[cols-i-1] ]\n",
      "2024-03-05 16:48:26,559 - pygigicar - INFO - Starting with EGv=0.374567\n",
      "2024-03-05 16:48:26,567 - pygigicar - INFO - gigicar component: 0/53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wc\n",
      "tensor(0.0029)\n",
      "init sources\n",
      "tensor(9.0831e-15)\n",
      "loss\n",
      "tensor(-0.7384, grad_fn=<SumBackward0>)\n",
      "loss\n",
      "tensor(-0.7386, grad_fn=<SumBackward0>)\n",
      "loss\n",
      "tensor(-0.7389, grad_fn=<SumBackward0>)\n",
      "loss\n",
      "tensor(-0.7391, grad_fn=<SumBackward0>)\n",
      "loss\n",
      "tensor(-0.7393, grad_fn=<SumBackward0>)\n",
      "loss\n",
      "tensor(-0.7395, grad_fn=<SumBackward0>)\n",
      "loss\n",
      "tensor(-0.7398, grad_fn=<SumBackward0>)\n",
      "loss\n",
      "tensor(-0.7400, grad_fn=<SumBackward0>)\n",
      "loss\n",
      "tensor(-0.7402, grad_fn=<SumBackward0>)\n",
      "loss\n",
      "tensor(-0.7404, grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 339\u001b[0m\n\u001b[1;32m    336\u001b[0m idx_np \u001b[38;5;241m=\u001b[39m idx\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    338\u001b[0m \u001b[38;5;66;03m# Continue with the rest of your PyTorch code...\u001b[39;00m\n\u001b[0;32m--> 339\u001b[0m ICOutMax, TCMax \u001b[38;5;241m=\u001b[39m \u001b[43mgigicar\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m    343\u001b[0m TCMax \u001b[38;5;241m=\u001b[39m TCMax\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "Cell \u001b[0;32mIn[1], line 217\u001b[0m, in \u001b[0;36mgigicar\u001b[0;34m(FmriMatr, ICRefMax)\u001b[0m\n\u001b[1;32m    215\u001b[0m     wx \u001b[38;5;241m=\u001b[39m GICA\u001b[38;5;241m.\u001b[39mW\u001b[38;5;241m.\u001b[39mstate_dict()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    216\u001b[0m     Source \u001b[38;5;241m=\u001b[39m wx \u001b[38;5;241m@\u001b[39m Y\n\u001b[0;32m--> 217\u001b[0m     gradients\u001b[38;5;241m.\u001b[39mappend(\u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39marray(grrs))\n\u001b[1;32m    218\u001b[0m     ICOutMax[ICnum, :] \u001b[38;5;241m=\u001b[39m Source\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m    219\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msub_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_grads.npy\u001b[39m\u001b[38;5;124m'\u001b[39m,np\u001b[38;5;241m.\u001b[39marray(gradients))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.linalg import norm\n",
    "import nibabel as nib\n",
    "import logging\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "a = 0.5\n",
    "b = 1 - a\n",
    "EGv = 0.3745672075\n",
    "ErChuPai = 2 / 3.141592653589793  \n",
    "\n",
    "\n",
    "\n",
    "def joint_loss(sources, mag_norm, reference, m):\n",
    "    #m = number of time steps\n",
    "    #reference = group map\n",
    "    #y3 = output\n",
    "    #c = magnitude normalization\n",
    "    #Cosy1 = torch.cosh(sources)\n",
    "    #logCosy1 = torch.log(Cosy1)\n",
    "    #EGy1 = logCosy1.mean()\n",
    "    #Negama = EGy1 - EGv\n",
    "    #Jy1 = (EGy1 - EGv)**2\n",
    "    #KwDaoshu = ErChuPai * mag_norm * (1 / (1 + (mag_norm * Jy1)**2))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #normalize weights for testing, normalize sources: check diff of sources@ref.t\n",
    "    loss = -(a * ErChuPai * torch.arctan(mag_norm * nege(sources)) + b * (1 / m) * sources.t() @ reference)\n",
    "    #loss = (a * KwDaoshu * 2 * Negama * EYgy + b * Simgrad.squeeze())\n",
    "    return loss\n",
    "\n",
    "\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "\n",
    "\n",
    "class gigICA(torch.nn.Module):\n",
    "    #init_sources = y1, init_weights = 2c, mag_norm = c, m = m\n",
    "    def __init__(self, init_sources, init_weights, dim, mag_norm, m):\n",
    "        super().__init__()\n",
    "        self.W = nn.Linear(init_weights.shape[0], 1)\n",
    "        self.W.weight = nn.parameter.Parameter(init_weights.reshape([1,-1]))\n",
    "        self.mag_norm = mag_norm \n",
    "        self.m = m\n",
    "\n",
    "    def forward(self, X, reference, last_sources):\n",
    "        sources = self.W(X)\n",
    "        #Simgrad = (1 / self.m) * X @ reference.t()\n",
    "        Eyr = 1/self.m * (sources.squeeze() @ reference.squeeze())\n",
    "        \n",
    "        \n",
    "        Simgrad = (1 / self.m) * X.t() @ reference\n",
    "        \n",
    "        return sources\n",
    "        \n",
    "        \n",
    "'''\n",
    "iternum = 10\n",
    "    \n",
    "#wc = wc / norm(wc)\n",
    "#y1 = wc.t() @ Y     \n",
    "Cosy1 = torch.cosh(y1)\n",
    "logCosy1 = torch.log(Cosy1)\n",
    "EGy1 = logCosy1.mean()\n",
    "Negama = EGy1 - EGv\n",
    "#as input\n",
    "#dim = y1.shape[0] if len(y1.shape) > 1 else y1.shape[0]\n",
    "EYgy = (1 / m) * Y @ (torch.tanh(y1)).t()\n",
    "Jy1 = (EGy1 - EGv)**2\n",
    "KwDaoshu = ErChuPai * c * (1 / (1 + (c * Jy1)**2))\n",
    "Simgrad = (1 / m) * Y @ reference.t()\n",
    "\n",
    "\n",
    "Gradient calculation:\n",
    "\n",
    "g = a * KwDaoshu * 2 * Negama * EYgy + b * Simgrad#.view(Simgrad.shape[0], 1)\n",
    "g_norm = torch.sqrt(g.T@g)#torch.linalg.norm(g)\n",
    "d = g / g_norm\n",
    "wx = wc + Nemda * d #wc.view(wc.shape[0], 1)\n",
    "wx = wx / norm(wx)\n",
    "y3 = wx.t() @ Y\n",
    "\n",
    "\n",
    "Loss computation:\n",
    "#Loss term\n",
    "PreObjValue = a * ErChuPai * torch.arctan(c * nege(y3)) + b * (1 / m) * y3 @ reference.t()\n",
    "ObjValueChange = PreObjValue - IniObjValue\n",
    "ftol = 0.02\n",
    "dg = g.t() @ d\n",
    "#In body of loop\n",
    "ArmiCondiThr = Nemda * ftol * dg\n",
    "if ObjValueChange < ArmiCondiThr:\n",
    "    Nemda = Nemda / 2\n",
    "    continue\n",
    "if torch.allclose(wc.t() @ wx, torch.zeros(1), atol=1e-5):\n",
    "    break\n",
    "elif itertime == iternum:\n",
    "    break\n",
    "IniObjValue = PreObjValue\n",
    "y1 = y3\n",
    "wc = wx\n",
    "itertime = itertime + 1\n",
    "'''      \n",
    "        \n",
    "def gigicar(FmriMatr, ICRefMax):\n",
    "    # Convert numpy arrays to PyTorch tensors\n",
    "    FmriMatr = torch.tensor(FmriMatr, dtype=torch.float64)\n",
    "    ICRefMax = torch.tensor(ICRefMax, dtype=torch.float64)\n",
    "\n",
    "    # Extract dimensions\n",
    "    n, m = FmriMatr.shape\n",
    "    n2, m2 = ICRefMax.shape\n",
    "\n",
    "    # Subtract mean from observed data\n",
    "    #FmriMat = FmriMatr - FmriMatr.mean(dim=1, keepdim=True)\n",
    "    FmriMat=FmriMatr - torch.tile(torch.mean(FmriMatr,1),(m,1)).T\n",
    "    # Calculate covariance matrix\n",
    "    CovFmri = (FmriMat @ FmriMat.t()) / m\n",
    "\n",
    "    # Perform PCA reduction on signal\n",
    "    D, E = torch.linalg.eig(CovFmri)\n",
    "\n",
    "    #D = D[:, 0].real if len(D.shape) > 1 else D.real  # Extract real parts of eigenvalues\n",
    "    EsICnum = ICRefMax.shape[0]\n",
    "    D = D.real\n",
    "    # Sort eigenvalues and eigenvectors\n",
    "    index = D.argsort()\n",
    "    eigenvalues = D[index]\n",
    "    cols=E.shape[1]\n",
    "    Esort=torch.zeros(E.shape)\n",
    "    dsort=torch.zeros(eigenvalues.shape)\n",
    "    for i in range(cols):\n",
    "        Esort[:,i] = E[:,index[cols-i-1] ]\n",
    "        dsort[i]   = D[index[cols-i-1] ]\n",
    "\n",
    "\n",
    "    thr = 0  # Set your threshold value here\n",
    "    numpc = (dsort > thr).sum()\n",
    "\n",
    "    # Perform PCA for selected components\n",
    "    Epart = Esort[:, :numpc]#.real\n",
    "    dpart = dsort[:numpc]\n",
    "    Lambda_part = torch.diag(dpart)#.real\n",
    "    # Whitening source signal\n",
    "    tmp = torch.sqrt(Lambda_part)\n",
    "    Lambda_inv = torch.linalg.inv(torch.sqrt(Lambda_part)) \n",
    "    WhitenMatrix = Lambda_inv @ Epart.t()\n",
    "    Y = WhitenMatrix @ FmriMat\n",
    "    if thr<1e-10 and numpc<n:\n",
    "        for i in range(Y.shape[0]):\n",
    "            Y[i,:]=Y[i,:]/torch.std(Y[i,:])\n",
    "    # Normalize source signal\n",
    "    #Y = F.normalize(Y, dim=1)\n",
    "    # Normalize reference signals\n",
    "    ICRefMaxC=ICRefMax - torch.tile(torch.mean(ICRefMax,1), (m2, 1)).T\n",
    "    ICRefMaxN=torch.zeros((EsICnum,m2))\n",
    "    for i in range(EsICnum):\n",
    "        ICRefMaxN[i,:]=ICRefMaxC[i,:]/torch.std(ICRefMaxC[i,:])\n",
    "    #ICRefMaxN = (ICRefMax - ICRefMax.mean(dim=1, keepdim=True)) / ICRefMax.std(dim=1, keepdim=True)\n",
    "\n",
    "    # Computing negentropy\n",
    "    NegeEva = torch.zeros((EsICnum, 1))\n",
    "    for i in range(EsICnum):\n",
    "        NegeEva[i] = nege(ICRefMaxN[i, :])\n",
    "\n",
    "    iternum = 10\n",
    "    a = 0.5\n",
    "    b = 1 - a\n",
    "    EGv = 0.3745672075\n",
    "    ErChuPai = 2 / 3.141592653589793\n",
    "\n",
    "    ICOutMax = torch.zeros((EsICnum, m))\n",
    "    logger.info(\"Starting with EGv=%f\" % EGv)\n",
    "    \n",
    "    gradients = []\n",
    "    for ICnum in range(2):\n",
    "        logger.info('gigicar component: %d/%d' % (ICnum, EsICnum))\n",
    "        reference = ICRefMaxN[ICnum, :]\n",
    "        wc = (reference @ torch.linalg.pinv(Y)).t()\n",
    "        wc = wc / norm(wc)\n",
    "        print(\"wc\")\n",
    "        print(torch.mean(wc))\n",
    "        last_sources = wc.t() @ Y\n",
    "        EyrInitial = (1 / m) * (last_sources) @ reference.t()\n",
    "        NegeInitial = nege(last_sources)\n",
    "        mag_norm = (torch.tan((EyrInitial * 3.141592653589793) / 2)) / NegeInitial\n",
    "        IniObjValue = a * ErChuPai * torch.arctan(mag_norm * NegeInitial) + b * EyrInitial\n",
    "\n",
    "        itertime = 1\n",
    "        Nemda = 1\n",
    "        print(\"init sources\")\n",
    "        print(torch.mean(last_sources))\n",
    "        GICA = gigICA(last_sources,wc,0,mag_norm,m)\n",
    "        \n",
    "        \n",
    "        optimizer = torch.optim.SGD(GICA.parameters(), lr=.001)\n",
    "        grrs = []\n",
    "        for i in range(iternum):\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            sources = GICA(Y.t(),reference.reshape([-1,1]), last_sources.reshape([-1,1]))\n",
    "            loss = joint_loss(sources, mag_norm, reference.reshape([-1,1]), m).sum()\n",
    "            loss.backward()\n",
    "            print(\"loss\")\n",
    "            print(loss)\n",
    "            gtmp = GICA.W.weight.grad.cpu().numpy()[0]\n",
    "            grrs.append(gtmp)\n",
    "            optimizer.step()\n",
    "            #Weight norm here...\n",
    "            #GICA.W.weight = torch.nn.Parameter(GICA.W.weight/norm(GICA.W.weight))\n",
    "            itertime = itertime + 1\n",
    "        wx = GICA.W.state_dict()['weight']\n",
    "        Source = wx @ Y\n",
    "        gradients.append(np.array(grrs))\n",
    "        ICOutMax[ICnum, :] = Source.squeeze()\n",
    "    np.save(f'{output_dir}/{sub_id}_grads.npy',np.array(gradients))\n",
    "    TCMax = (1 / m) * FmriMatr @ ICOutMax.t()\n",
    "    return ICOutMax, TCMax\n",
    "\n",
    "\n",
    "def nege(x):\n",
    "    y = torch.log(torch.cosh(x))\n",
    "    E1 = y.mean()\n",
    "    E2 = 0.3745672075\n",
    "    return (E1 - E2)**2\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# SETUP LOGGER\n",
    "########################################################################\n",
    "\n",
    "\n",
    "\n",
    "DEFAULT_REFERENCE_FN = 'pooled_47.nii'\n",
    "DEFAULT_EXAMPLE_FN = 'example.nii'\n",
    "FORMAT = '%(asctime)-15s %(message)s'\n",
    "logging.basicConfig(filename='pygigicar.log',level=logging.INFO)\n",
    "logging.basicConfig(format=FORMAT)\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.INFO)\n",
    "\n",
    "# create formatter\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# add formatter to ch\n",
    "ch.setFormatter(formatter)\n",
    "\n",
    "\n",
    "logger = logging.getLogger('pygigicar')\n",
    "logger.setLevel(logging.INFO)\n",
    "# add ch to logger\n",
    "logger.handlers = []\n",
    "logger.addHandler(ch)\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# CALL FUNCTIONS\n",
    "########################################################################\n",
    "'''\n",
    "if len(sys.argv) != 6:\n",
    "    print(\"Usage: python gigicar.py sub_id func_file out_dir mask_file template_file \")\n",
    "    print(sys.argv)\n",
    "    sys.exit()\n",
    "'''\n",
    "#sub_id = sys.argv[1]\n",
    "sub_id = '000300655084'\n",
    "sub_id = \"001312269620\"\n",
    "#sub_id = 'test'\n",
    "print(f\"sub_id:{sub_id}\")\n",
    "\n",
    "#func_file = sys.argv[2]\n",
    "func_file = '/data/qneuromark/Data/FBIRN/ZN_Neuromark/ZN_Prep_fMRI/'+sub_id+'/SM.nii'\n",
    "print(f\"func_file:{func_file}\")\n",
    "\n",
    "#output_dir = sys.argv[3]\n",
    "output_dir = './out/'\n",
    "print(f\"output_dir:{output_dir}\")\n",
    "\n",
    "#mask_file = sys.argv[4]\n",
    "mask_file = '/data/users2/jwardell1/nshor_docker/examples/fbirn-project/FBIRN/group_mean_masks/mask_resampled.nii'\n",
    "print(f\"mask_file:{mask_file}\")\n",
    "\n",
    "#template_file = sys.argv[5]\n",
    "template_file = '/data/users2/jwardell1/ica-torch-gica/sa_script_work/gica/group_level_analysis/Neuromark_fMRI_1.0.nii'\n",
    "print(f\"template_file:{template_file}\")\n",
    "\n",
    "'''\n",
    "if not os.path.isfile(func_file):\n",
    "    print(\"Error: subject's preprocessed fMRI file not found.\")\n",
    "    sys.exit()\n",
    "\n",
    "\n",
    "if not os.path.isdir(output_dir):\n",
    "    print(\"Error: output dir not found.\")\n",
    "    sys.exit()\n",
    "\n",
    "\n",
    "if not os.path.isfile(mask_file):\n",
    "    print(\"Error: mask file not found.\")\n",
    "    sys.exit()\n",
    "\n",
    "\n",
    "if not os.path.isfile(template_file):\n",
    "    print(\"Error: template file not found.\")\n",
    "    sys.exit()\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load images\n",
    "src_img = nib.load(func_file)\n",
    "src_data = torch.tensor(src_img.get_fdata(), dtype=torch.float64)\n",
    "\n",
    "ref_img = nib.load(template_file)\n",
    "ref_data = torch.tensor(ref_img.get_fdata(), dtype=torch.float64)\n",
    "\n",
    "mask_img = nib.load(mask_file)\n",
    "mask_data = torch.tensor(mask_img.get_fdata(), dtype=torch.float64)\n",
    "\n",
    "# Create idx tensor\n",
    "idx = torch.nonzero(mask_data).t()\n",
    "\n",
    "# Mask source and reference images\n",
    "src_data = src_data[idx[0], idx[1], idx[2], :].t()\n",
    "print(f'src_data.shape {src_data.shape}')\n",
    "\n",
    "ref_data = ref_data[idx[0], idx[1], idx[2], :].t()\n",
    "print(f'ref_data.shape {ref_data.shape}')\n",
    "\n",
    "# Convert idx to numpy for compatibility with existing code\n",
    "idx_np = idx.cpu().numpy()\n",
    "\n",
    "# Continue with the rest of your PyTorch code...\n",
    "ICOutMax, TCMax = gigicar(src_data, ref_data)\n",
    "\n",
    "\n",
    "TCMax = TCMax.cpu().numpy()\n",
    "# Save time courses file\n",
    "tcfilename = f'{output_dir}/{sub_id}_TCMax_Torchified.npy'\n",
    "np.save(tcfilename, TCMax)\n",
    "\n",
    "# Reconstruct brain voxels\n",
    "xdim, ydim, zdim = mask_data.shape\n",
    "n_comp = ICOutMax.shape[0]\n",
    "image_stack = torch.zeros((xdim, ydim, zdim, n_comp))\n",
    "\n",
    "# Convert idx to numpy for compatibility with existing code\n",
    "idx_np = idx.cpu().numpy()\n",
    "\n",
    "image_stack[idx_np[0], idx_np[1], idx_np[2], :] = ICOutMax.t()\n",
    "\n",
    "# Save as nifti\n",
    "print(\"saving\")\n",
    "nifti_img = nib.Nifti1Image(image_stack.numpy(), affine=mask_img.get_qform())\n",
    "nifti_img.header.set_sform(mask_img.header.get_sform(), code=mask_img.get_qform('code')[1])\n",
    "nifti_img.header.set_qform(mask_img.header.get_qform(), code=mask_img.get_qform('code')[1])\n",
    "nifti_file = f'{output_dir}/{sub_id}_ICOutMax_Torchified_SQ.nii.gz'\n",
    "nib.save(nifti_img, nifti_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condaUpdatedPytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
